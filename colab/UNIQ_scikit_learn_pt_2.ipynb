{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNIQ_scikit-learn_pt_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introducing Scikit-Learn (ii)"
      ],
      "metadata": {
        "id": "LPrtgV2gu2QM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having completed a basic overview, we will now use Scikit-Learn to visualise  a few fundamental concepts in machine learning. These will include:\n",
        "* Bias-variance trade-off\n",
        "* Something else\n",
        "\n",
        "Thereafter, we will move to a real-world example to give you the opportunity to conduct a mock data science problem yourself. There is no expectation on any particular scores your models might achieve, the only goal is that you get a feel for how one might approach an ML problem, and what tools exist to score your model."
      ],
      "metadata": {
        "id": "A_XNU6VFvHOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bias-variance tradeoff"
      ],
      "metadata": {
        "id": "og9HvadR08Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "QmsnbqMz0_tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scoring functions\n",
        "\n",
        "\n",
        "*   Precision-Recall curves\n",
        "*   Receiver operating characteristic curves\n",
        "*   Confusion matrices\n",
        "\n"
      ],
      "metadata": {
        "id": "WzGIHBDCr6zN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example real-world problem"
      ],
      "metadata": {
        "id": "5RWbK5Fu1Bag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine learning is prevelant in today's scientific landscape, with applications spanning Biomedical engineering, astrostatistics, finance, the entertainment industry, and countless other disciplines. \n",
        "\n",
        "In this tutorial we will consider how one might use ML to classify acoustics into categories. This type of analysis involves:\n",
        "\n",
        "\n",
        "\n",
        "1.   Data collection and pre-processing\n",
        "2.   Feature generation\n",
        "3.   Model selection\n",
        "4.   Model training\n",
        "5.   Analysing model performance\n",
        "\n",
        "You will find in practice that the key to unlocking good predictive insights is the quality and quantity of data used. We will however not make this the focal point, and assume the data is clean within reason.\n",
        "\n",
        "If you are interested in common difficulties encountered with data processing, please refer to [XYZ]\n",
        "\n"
      ],
      "metadata": {
        "id": "P0N8pgRI3ikP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem definition\n",
        "#### Mosquito acoustic detection: can we use machine learning to detect mosquitoes from the sound of their acoustic wingbeat?\n",
        "\n",
        "Mosquitoes are responsible over xyz yyz [cite]. As a byproduct of their behaviour patterns, they produce a characteristic buzz from their flight, mating calls, and other etc... The idea is to leverage this sound with cheap sensors (acoustic smartphone sensors in an IoT network) to be able to estimate the prevelance of mosquitoes in a particular area. To do this, we need algorithms capable of distinguishing the buzz of mosquito from its surroundings. In this challenge we will show how it is possible to use Scikit-learn to build a basic classifier to achieve this."
      ],
      "metadata": {
        "id": "Rc6fC_-F3WqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data collection and pre-processing\n",
        "\n",
        "This dataset is part of xyz, we will download it here as follows:"
      ],
      "metadata": {
        "id": "j9MLBeU8p7Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget something something"
      ],
      "metadata": {
        "id": "UC9Zik-FoFFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-process by removing the mean and standard deviation. We will store the results in xyz to then apply to the test data. Note that there are several schemes for normalisation:\n",
        "\n",
        "* Normalise per sample/recording. This is similar to how images will be normalised by their intensity relative to only themselves\n",
        "* As above, but normalise in batches [read more about this]\n",
        "* Use the entire dataset to remove offset statistics such as the mean, and standardise the variance. When predicting over test data, we perform the same transform to the test data.\n",
        "\n",
        "There is no universal or accepted method of normalising audio data, as there are benefits and drawbacks to each. You may experiment with different schemes. However, it is important to consider that some ML algorithms are expected to operate in a certain range, and require re-scaling to appropriate units. An example of this is the SVM because XYZ"
      ],
      "metadata": {
        "id": "Qmt_6z9EqHZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By default, let us remove the mean and standard deviation per sample.\n",
        "..."
      ],
      "metadata": {
        "id": "iOf10gu3qXnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Feature generation\n",
        "In general, features extracted will vary from domain to domain, and we could opt to go for highly hand-crafted descriptors or let our inference models learn their own representations entirely. Current SOTA performance tends to use something in between, though this is highly dependent on the domain\n",
        "\n",
        "For creating features we have several options to explore with audio:\n",
        "\n",
        "\n",
        "1.   Learn hierarchical feature representations with neural networks from:\n",
        "  1. Raw audio waveform\n",
        "  2. Intermediate feature representations\n",
        "\n",
        "2. Extract descriptive features. In audio these could be MFCCs -- a bandpass of non-linearly spaced frequency features, based on the mel-scale (melodic scale), where humans perceive each band as evenly spaced in blab bla bla [CITE + CORRECT]. There are many features we could go for, such as zero crossing rate, spectral power, fluctuations in xyz - for a complete list you could refer to OpenSMILE. \n",
        "\n",
        "2.   List item\n",
        "\n",
        "\n",
        "2.   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "AKaXjyTd8kyu"
      }
    }
  ]
}